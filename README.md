<div align="center">
<picture>
    <source srcset="./assets/images/condense-main.png">
    <img src="./assets/images/condense-main.png" alt="Neural Condense Subnet" style="width:800px;">

</picture>
</div>

<div align="center">

# âš¡ 

</div>


## ğŸŒŸ Key Features:

### âš¡ Subnet as an Accelerate Adapter for LLM Inference
- ğŸŒ **Seamless Integration**: Effortlessly integrates with LLM inference engines, such as transformers ğŸ¤—, vllm.
- ğŸ§© **Token Compression**: The subnet API compresses long sequences of natural language tokens into soft tokens.
- ğŸ›ï¸ **Decentralized Network**: The subnet is a decentralized network that allows miners to contribute to the compression process.
- ğŸ“Š **Tiered System**: The subnet has a tiered system, with a research tier for experimentation and an inference tier for production-scale use. Incentive distribution is splitted for each tier.
- ğŸ“ **Benchmarking and Validation**: The subnet owner defines synthetic metrics to benchmark minersâ€™ performance, ensuring quality and efficiency.

### âš™ï¸ Node Tiers


| **Tier**       | **Purpose**                           | **Context Size**         | **Incentive Percentage**     | **Supporting Models**               |
|----------------|---------------------------------------|---------------------------|---------------|--------------------------------------|
| `research`     | Warmup tier for new LLM model releases | Up to 2500                  | `100%`  | `mistralai/Mistral-7B-Instruct-v0.2` |
| `inference_0`  | Optimized for **long context** in popular LLMs | Up to 3000 characters       | `0%`         | `mistralai/Mistral-7B-Instruct-v0.2` |
| `inference_1`  | Optimized for **very long context** in popular LLMs | Up to 7000 characters       | `0%`         | `mistralai/Mistral-7B-Instruct-v0.2` |

*Supporting models can be flexibly added based on tailored need.*

On the early launch of the subnet, we distribute all the incentives to the research tier to encourage miners to join the network and be familiar with the subnet. The subnet owner will gradually distribute the incentives to the inference tiers as the subnet grows.

--- 


### ğŸ”’ Subnet as a Data Encryption Layer for Bittensor
- **Neural Encrypted Conversations:** The subnet offers an additional benefit regarding privacy. If users or companies utilize a subnet to transform their context into condensed tokens before sending them to other LLM services, this approach can help prevent context leaks. The transformation increases the computational complexity, making it more difficult for unauthorized entities to extract the original context.


## ğŸ“š Documentation
- **Setup for miners**: [Miner Setup](./docs/miner.md)
- **Setup for validators**: [Validator Setup](./docs/validator.md)
